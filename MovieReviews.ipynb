{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MAKING ALL NECESSARY IMPORTS #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.wsd import lesk\n",
    "#from nltk.parse import CoreNLPParser\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from nltk.parse.corenlp import CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ NLP PIPELINE ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') + list(string.punctuation)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenization(sentence):\n",
    "    tokens = [i for i in nltk.word_tokenize(sentence.lower()) if i not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtains hypernyms\n",
    "def WordNetHypernyms(sentence, word_tokens):\n",
    "    # Creates dictionary for hypernyms\n",
    "    hypernyms_list = []\n",
    "    \n",
    "    # Populates the above dictionaries according to the word senses associated with them\n",
    "    for token in word_tokens:\n",
    "        # Extracts best sense for each word using LESK\n",
    "        best_sense = lesk(sentence, token)\n",
    "        \n",
    "        if best_sense is not None:\n",
    "            # Obtains Hypernyms\n",
    "            if best_sense.hypernyms() != []:\n",
    "                hypernyms_list.append(best_sense.hypernyms()[0].lemmas()[0].name())\n",
    "            \n",
    "    return hypernyms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP_Pipeline(sentence):\n",
    "    word_tokens = Tokenization(sentence)\n",
    "    hypernyms = WordNetHypernyms(sentence, word_tokens)\n",
    "    return hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = \"A soldier-of-fortune steals some Russian nerve gas from Afghanistan, and brings it to the U.S. to be analyzed. A greedy millionaire rancher finds out about it and sets out to steal it.\"\n",
    "# sample_hypernyms = ['combatant', 'country', 'fuel', 'change', 'rich_person', 'farmer', 'feeling', 'gain']\n",
    "# print('Sample Text: ' + sample_text)\n",
    "# print('Extracted hypernyms: combatant, country, fuel, change, rich_person, farmer, feeling, gain')\n",
    "#print(NLP_Pipeline(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MOVIE MATCHING BETWEEN DATASETS #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_summaries = pd.read_csv(r'Data/MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "df_movies_summaries.columns = ['Wikipedia ID', 'Freebase ID', 'Movie name', 'Release date', 'BO Revenue', 'Runtime', 'Language', 'Countires', 'Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/ml-1m/movies.dat') as dat_file, open('Data/ml-1m/movies.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        row = [field.strip() for field in line.split('::')]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "df_movies_ratings = pd.read_csv('Data/ml-1m/movies.csv', sep=',', encoding='latin-1')\n",
    "df_movies_ratings.columns = ['movie_id', 'title', 'genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_ratings['title'] = df_movies_ratings['title'].str.lower()\n",
    "df_movies_summaries['Movie name'] = df_movies_summaries['Movie name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_dict = {}\n",
    "for ix in df_movies_ratings.index:\n",
    "    movie_id = df_movies_ratings.loc[ix]['movie_id']\n",
    "    movie_name = df_movies_ratings.loc[ix]['title']\n",
    "    temp_list = movie_name.split('(')\n",
    "    movie_name_new = temp_list[0]\n",
    "    movie_name_new = movie_name_new.replace(' ', '')\n",
    "    movie_ratings_dict[movie_name_new] = movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_ratings_summary = {}\n",
    "for ix in df_movies_summaries.index:\n",
    "    movie_name = df_movies_summaries.loc[ix]['Movie name']\n",
    "    movie_id_summary = df_movies_summaries.loc[ix]['Wikipedia ID']\n",
    "    if movie_name in movie_ratings_dict:\n",
    "        df_movies_summaries.loc[[ix],['Ratings present']] = 'Y'\n",
    "        movie_id_rating = movie_ratings_dict[movie_name]\n",
    "        df_movies_summaries.loc[[ix],['Movie ID Ratings']] = movie_id_rating\n",
    "        movie_id_ratings_summary[movie_id_rating] = movie_id_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_summaries.to_csv('Output/df_movies_summaries.csv')\n",
    "with open('Output/movie-id-ratings-summary.txt', 'w') as f:\n",
    "    print(movie_id_ratings_summary, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies_summaries.nunique())\n",
    "print(len(movie_id_ratings_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### GENERATING HYPERNYMS FOR MOVIES FOR WHICH WE HAVE RATINGS DATA ################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data/MovieSummaries/plot_summaries.txt\"\n",
    "counts_dict = {}\n",
    "movies_dict = {}\n",
    "\n",
    "with open(filename, encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        hypernyms_list = []\n",
    "        values = line.split(\"\\t\")\n",
    "        synopsis = values[1]\n",
    "        movieID = values[0]\n",
    "        if movieID in str(movie_id_ratings_summary.values()):\n",
    "            hypernyms_list = NLP_Pipeline(synopsis)\n",
    "            movies_dict[movieID] = hypernyms_list\n",
    "            for hypernym in hypernyms_list:\n",
    "                counts_dict[hypernym] = counts_dict.get(hypernym, 0) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "#print(len(movies_dict))\n",
    "with open('Output/movies-dict.txt', 'w', encoding='utf8') as f:\n",
    "    print(movies_dict, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict_sorted = sorted(counts_dict, key=counts_dict.get, reverse=True)\n",
    "top_1000_counts = counts_dict_sorted[0:1000]\n",
    "print(len(top_100_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(top_1000_counts)\n",
    "with open('Output/top-1000-counts.txt', 'w') as f:\n",
    "    print(top_1000_counts, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## GENERATING THE MOVIE CONCEPTS ARRAY FOR COLLABORATIVE FILTERING #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_concepts_array = np.zeros(shape=(len(movies_dict), len(top_1000_counts)))\n",
    "row_number = -1\n",
    "for movie in movies_dict:\n",
    "    row_number = row_number + 1\n",
    "    col_number = -1\n",
    "    concepts_list = movies_dict[movie]\n",
    "    for concept in top_1000_counts:\n",
    "        col_number = col_number + 1\n",
    "        if concept in concepts_list:\n",
    "            movies_concepts_array[row_number][col_number] = 1\n",
    "\n",
    "# print(movies_concepts_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/movies-concepts-array.txt', 'w') as f:\n",
    "    print(movies_concepts_array, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### GETTING THE RATINGS DATA #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = dict()\n",
    "with open('Data/ml-1m/ratings.dat', encoding='utf8') as dat_file, open('Data/ml-1m/ratings.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        row = [field.strip() for field in line.split('::')]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "df_ratings = pd.read_csv('Data/ml-1m/ratings.csv', sep=',', encoding='latin-1')\n",
    "df_ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000208\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "# df_ratings = df_ratings[0:40000]\n",
    "# print(len(df_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### GENERATING A USER RATING MATRIX FOR REVIEWS OF MOVIES THAT HAVE SUMMARY INFORMATION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "ratings_new_list = []\n",
    "for ix in df_ratings.index:\n",
    "    movie_id = df_ratings.loc[ix]['movie_id']\n",
    "    if float(movie_id) in movie_id_ratings_summary:\n",
    "        df_ratings.loc[[ix],['Summary Present']] = 'Y'\n",
    "        df_ratings.loc[[ix],['Movie Summary ID']] = int(movie_id_ratings_summary[float(movie_id)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings[(df_ratings['Summary Present'] == 'Y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings, df_ratings_test = train_test_split(df_ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv('Output/df_ratings.csv')\n",
    "df_ratings_test = pd.read_csv('Output/df_ratings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_grouped = df_ratings.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6015\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ratings_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = np.zeros(shape=(len(df_ratings_grouped), len(movies_dict)))\n",
    "key = 0\n",
    "row = -1\n",
    "existing_users = []\n",
    "for ix in df_ratings.index:\n",
    "    user_id = df_ratings.loc[ix]['user_id']\n",
    "    if user_id not in existing_users:\n",
    "        existing_users.append(user_id)\n",
    "        row = row + 1\n",
    "        users_dict[user_id] = row\n",
    "\n",
    "    movie_id = df_ratings.loc[ix]['movie_id']\n",
    "    ratings_val = df_ratings.loc[ix]['rating']\n",
    "\n",
    "    if float(movie_id) in movie_id_ratings_summary:\n",
    "        movie_id_summary = movie_id_ratings_summary[movie_id]\n",
    "        if str(movie_id_summary) in movies_dict:\n",
    "            col = list(movies_dict).index(str(movie_id_summary))\n",
    "            ratings_matrix[row][col] = ratings_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/users-dict.txt', 'w') as f:\n",
    "    print(users_dict, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/ratings-matrix.txt', 'w') as f:\n",
    "    print(ratings_matrix, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "# ratings_matrix = np.zeros(shape=(len(df_ratings_grouped), len(movies_dict)))\n",
    "# f = open('ratings-matrix.txt', 'r')\n",
    "# row_num = 0\n",
    "# col_num = 0\n",
    "# for line in f:\n",
    "#     for i in range(len(line)):\n",
    "#         if line[i] == '0' or line[i] == '1' or line[i] == '2' or line[i] == '3' or line[i] == '4' or line[i] == '5':\n",
    "#             ratings_matrix[row_num][col_num] = int(line[i])\n",
    "#             col_num = col_num + 1\n",
    "#         if line[i] == ']':\n",
    "#             row_num = row_num + 1\n",
    "#             col_num = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(movie_1, movie_2):\n",
    "    if movie_1 not in movies_dict or movie_2 not in movies_dict:\n",
    "        return 0\n",
    "    movie_num_1 = list(movies_dict).index(movie_1)\n",
    "    movie_num_2 = list(movies_dict).index(movie_2)\n",
    "    a = movies_concepts_array[movie_num_1]\n",
    "    b = movies_concepts_array[movie_num_2]\n",
    "    if norm(a) == 0 or norm(b) == 0:\n",
    "        return 0\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_prediction(user_id, movie_id):\n",
    "    movie_id = str(movie_id)\n",
    "    movie_flag = False\n",
    "\n",
    "    # if movie_id not in movies_dict.keys():\n",
    "    #     return 0\n",
    "    for key, value in movies_dict.items():\n",
    "        if movie_id == key:\n",
    "            movie_flag = True\n",
    "    \n",
    "    if not movie_flag:\n",
    "        return 0\n",
    "    if user_id not in users_dict:\n",
    "        return 0\n",
    "    \n",
    "    pred_rating = 0\n",
    "    count = 0\n",
    "\n",
    "    user_ix = list(users_dict).index(user_id)\n",
    "\n",
    "    for key, value in movies_dict.items():\n",
    "        if key == movie_id:\n",
    "            continue\n",
    "        else:\n",
    "            movie_ix = list(movies_dict).index(key)\n",
    "            movie_sim = cosine_sim(key, movie_id)\n",
    "            if movie_sim > 0:\n",
    "                if ratings_matrix[user_ix][movie_ix] != 0:\n",
    "                    count = count + movie_sim\n",
    "                    pred_rating = pred_rating + movie_sim * ratings_matrix[user_ix][movie_ix]\n",
    "    \n",
    "    if count != 0:\n",
    "        return pred_rating / count\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ratings = []\n",
    "count = 0\n",
    "for ix in df_ratings_test.index:\n",
    "    movie_id = df_ratings_test.loc[ix]['Movie Summary ID']\n",
    "    movie_id = str(int(movie_id))\n",
    "    user_id = df_ratings_test.loc[ix]['user_id']\n",
    "    pred_rating = ratings_prediction(user_id, movie_id)\n",
    "    pred_ratings.append(pred_rating)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_test['Predicted Ratings'] = pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_rating_list = []\n",
    "pred_rating_list = []\n",
    "for ix in df_ratings_test.index:\n",
    "    actual_rating = df_ratings_test.loc[ix]['rating']\n",
    "    pred_rating = df_ratings_test.loc[ix]['Predicted Ratings']\n",
    "    if pred_rating != 0:\n",
    "        actual_rating_list.append(actual_rating)\n",
    "        pred_rating_list.append(pred_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv('Output/df_ratings.csv')\n",
    "df_ratings_test.to_csv('Output/df_ratings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(actual_rating_list)):\n",
    "    if actual_rating_list[i] == round(pred_rating_list[i]):\n",
    "        correct = correct + 1\n",
    "    total = total + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30647723526061804\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print(correct/total)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12203f4631f1c8a04127b7540e373e2eec32b1de98b5a481febbb709a77e5f64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
