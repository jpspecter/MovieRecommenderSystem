{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MAKING ALL NECESSARY IMPORTS #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.wsd import lesk\n",
    "#from nltk.parse import CoreNLPParser\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from nltk.parse.corenlp import CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MOVIE MATCHING BETWEEN DATASETS #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_summaries = pd.read_csv(r'Data/MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "df_movies_summaries.columns = ['Wikipedia ID', 'Freebase ID', 'Movie name', 'Release date', 'BO Revenue', 'Runtime', 'Language', 'Countires', 'Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/ml-1m/movies.dat') as dat_file, open('Data/ml-1m/movies.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        row = [field.strip() for field in line.split('::')]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "df_movies_ratings = pd.read_csv('Data/ml-1m/movies.csv', sep=',', encoding='latin-1')\n",
    "df_movies_ratings.columns = ['movie_id', 'title', 'genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_ratings['title'] = df_movies_ratings['title'].str.lower()\n",
    "df_movies_summaries['Movie name'] = df_movies_summaries['Movie name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_dict = {}\n",
    "for ix in df_movies_ratings.index:\n",
    "    movie_id = df_movies_ratings.loc[ix]['movie_id']\n",
    "    movie_name = df_movies_ratings.loc[ix]['title']\n",
    "    temp_list = movie_name.split('(')\n",
    "    movie_name_new = temp_list[0]\n",
    "    movie_name_new = movie_name_new.replace(' ', '')\n",
    "    movie_ratings_dict[movie_name_new] = movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_ratings_summary = {}\n",
    "for ix in df_movies_summaries.index:\n",
    "    movie_name = df_movies_summaries.loc[ix]['Movie name']\n",
    "    movie_id_summary = df_movies_summaries.loc[ix]['Wikipedia ID']\n",
    "    if movie_name in movie_ratings_dict:\n",
    "        df_movies_summaries.loc[[ix],['Ratings present']] = 'Y'\n",
    "        movie_id_rating = movie_ratings_dict[movie_name]\n",
    "        df_movies_summaries.loc[[ix],['Movie ID Ratings']] = movie_id_rating\n",
    "        movie_id_ratings_summary[movie_id_rating] = movie_id_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_summaries.to_csv('Output/df_movies_summaries.csv')\n",
    "with open('Output/movie-id-ratings-summary.txt', 'w') as f:\n",
    "    print(movie_id_ratings_summary, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_movies_summaries.nunique())\n",
    "print(len(movie_id_ratings_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "rake = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "# text = \"The nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl  between the ages of 12 and 18 selected by lottery  for the annual Hunger Games. The tributes must fight to the death in an arena; the sole survivor is rewarded with fame and wealth. In her first Reaping, 12-year-old Primrose Everdeen is chosen from District 12. Her older sister Katniss volunteers to take her place. Peeta Mellark, a baker's son who once gave Katniss bread when she was starving, is the other District 12 tribute. Katniss and Peeta are taken to the Capitol, accompanied by their frequently drunk mentor, past victor Haymitch Abernathy. He warns them about the career tributes who train intensively at special academies and almost always win. During a TV interview with Caesar Flickerman, Peeta unexpectedly reveals his love for Katniss. She is outraged, believing it to be a ploy to gain audience support, as sponsors may provide in-Games gifts of food, medicine, and tools. However, she discovers Peeta meant what he said. The televised Games begin with half of the tributes killed in the first few minutes; Katniss barely survives ignoring Haymitch's advice to run away from the melee over the tempting supplies and weapons strewn in front of a structure called the Cornucopia. Peeta forms an uneasy alliance with the four Careers. They later find Katniss and corner her up a tree. Rue, hiding in a nearby tree, draws her attention to a poisonous tracker jacker nest hanging from a branch. Katniss drops it on her sleeping besiegers. They all scatter, except for Glimmer, who is killed by the insects. Hallucinating due to tracker jacker venom, Katniss is warned to run away by Peeta. Rue cares for Katniss for a couple of days until she recovers. Meanwhile, the alliance has gathered all the supplies into a pile. Katniss has Rue draw them off, then destroys the stockpile by setting off the mines planted around it. Furious, Cato kills the boy assigned to guard it. As Katniss runs from the scene, she hears Rue calling her name. She finds Rue trapped and releases her. Marvel, a tribute from District 1, throws a spear at Katniss, but she dodges the spear, causing it to stab Rue in the stomach instead. Katniss shoots him dead with an arrow. She then comforts the dying Rue with a song. Afterward, she gathers and arranges flowers around Rue's body. When this is televised, it sparks a riot in Rue's District 11. President Snow summons Seneca Crane, the Gamemaker, to express his displeasure at the way the Games are turning out. Since Katniss and Peeta have been presented to the public as star-crossed lovers, Haymitch is able to convince Crane to make a rule change to avoid inciting further riots. It is announced that tributes from the same district can win as a pair. Upon hearing this, Katniss searches for Peeta and finds him with an infected sword wound in the leg. She portrays herself as deeply in love with him and gains a sponsor's gift of soup. An announcer proclaims a feast, where the thing each survivor needs most will be provided. Peeta begs her not to risk getting him medicine. Katniss promises not to go, but after he falls asleep, she heads to the feast. Clove ambushes her and pins her down. As Clove gloats, Thresh, the other District 11 tribute, kills Clove after overhearing her tormenting Katniss about killing Rue. He spares Katniss just this time...for Rue. The medicine works, keeping Peeta mobile. Foxface, the girl from District 5, dies from eating nightlock berries she stole from Peeta; neither knew they are highly poisonous. Crane changes the time of day in the arena to late at night and unleashes a pack of hound-like creatures to speed things up. They kill Thresh and force Katniss and Peeta to flee to the roof of the Cornucopia, where they encounter Cato. After a battle, Katniss wounds Cato with an arrow and Peeta hurls him to the creatures below. Katniss shoots Cato to spare him a prolonged death. With Peeta and Katniss apparently victorious, the rule change allowing two winners is suddenly revoked. Peeta tells Katniss to shoot him. Instead, she gives him half of the nightlock. However, before they can commit suicide, they are hastily proclaimed the victors of the 74th Hunger Games. Haymitch warns Katniss that she has made powerful enemies after her display of defiance. She and Peeta return to District 12, while Crane is locked in a room with a bowl of nightlock berries, and President Snow considers the situation.\"\n",
    "# rake.extract_keywords_from_text(text)\n",
    "# key_words_dict_scores = rake.get_word_degrees()\n",
    "# print(key_words_dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"Data/MovieSummaries/plot_summaries.txt\"\n",
    "# counts_dict = {}\n",
    "# movies_dict = {}\n",
    "# df_movies_concepts = pd.DataFrame()\n",
    "# data = []\n",
    "\n",
    "# with open(filename, encoding=\"utf8\") as file:\n",
    "#     for line in file:\n",
    "#         hypernyms_list = []\n",
    "#         values = line.split(\"\\t\")\n",
    "#         synopsis = values[1]\n",
    "#         movieID = values[0]\n",
    "#         if movieID in str(movie_id_ratings_summary.values()):\n",
    "#             rake.extract_keywords_from_text(synopsis)\n",
    "#             key_words_dict_scores = rake.get_word_degrees()\n",
    "#             keywords_list = list(key_words_dict_scores.keys())\n",
    "#             keywords_string = ' '.join([str(item) for item in keywords_list])\n",
    "#             data.append([movieID, keywords_string])\n",
    "#             movies_dict[movieID] = keywords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_movies_concepts = pd.DataFrame(data, columns=['Movie ID (Summary)', 'Keywords List'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_movies_concepts.to_csv('Output/df_movies_concepts.csv')\n",
    "#print(len(movies_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = CountVectorizer()\n",
    "# count_matrix = count.fit_transform(df_movies_concepts['Keywords List'])\n",
    "# cosine_sim_matrix = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "  \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "  \n",
    "VERB_CODES = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data/MovieSummaries/plot_summaries.txt\"\n",
    "counts_dict = {}\n",
    "movies_dict = {}\n",
    "df_movies_concepts = pd.DataFrame()\n",
    "data = []\n",
    "\n",
    "with open(filename, encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        values = line.split(\"\\t\")\n",
    "        synopsis = values[1]\n",
    "        movieID = values[0]\n",
    "        if movieID in str(movie_id_ratings_summary.values()):\n",
    "            data.append([movieID, synopsis])\n",
    "            movies_dict[movieID] = synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_concepts = pd.DataFrame(data, columns=['Movie ID (Summary)', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(text):\n",
    "  text = text.lower()\n",
    "  temp_sent =[]\n",
    "  words = nltk.word_tokenize(text)\n",
    "  tags = nltk.pos_tag(words)\n",
    "  for i, word in enumerate(words):\n",
    "      if tags[i][1] in VERB_CODES: \n",
    "          lemmatized = lemmatizer.lemmatize(word, 'v')\n",
    "      else:\n",
    "          lemmatized = lemmatizer.lemmatize(word)\n",
    "      if lemmatized not in stop_words and lemmatized.isalpha():\n",
    "          temp_sent.append(lemmatized)\n",
    "          \n",
    "  finalsent = ' '.join(temp_sent)\n",
    "  finalsent = finalsent.replace(\"n't\", \" not\")\n",
    "  finalsent = finalsent.replace(\"'m\", \" am\")\n",
    "  finalsent = finalsent.replace(\"'s\", \" is\")\n",
    "  finalsent = finalsent.replace(\"'re\", \" are\")\n",
    "  finalsent = finalsent.replace(\"'ll\", \" will\")\n",
    "  finalsent = finalsent.replace(\"'ve\", \" have\")\n",
    "  finalsent = finalsent.replace(\"'d\", \" would\")\n",
    "  return finalsent\n",
    "  \n",
    "df_movies_concepts[\"Summary Processed\"]= df_movies_concepts[\"Summary\"].apply(preprocess_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "  \n",
    "# Vectorizing pre-processed movie plots using TF-IDF\n",
    "tfidfvec = TfidfVectorizer()\n",
    "tfidf_movieid = tfidfvec.fit_transform((df_movies_concepts[\"Summary Processed\"]))\n",
    "  \n",
    "# Finding cosine similarity between vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_movieid, tfidf_movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/cosine-sim-matrix-2.txt', 'w', encoding='utf8') as f:\n",
    "    print(cosine_sim_matrix, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01703050798710823\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "for i in range(len(cosine_sim_matrix)):\n",
    "    for j in range(len(cosine_sim_matrix[0])):\n",
    "        total += cosine_sim_matrix[i][j]\n",
    "        count += 1\n",
    "\n",
    "average = total / count\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(movies_dict))\n",
    "with open('Output/movies-dict.txt', 'w', encoding='utf8') as f:\n",
    "    print(movies_dict, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### GETTING THE RATINGS DATA #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = dict()\n",
    "with open('Data/ml-1m/ratings.dat', encoding='utf8') as dat_file, open('Data/ml-1m/ratings.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        row = [field.strip() for field in line.split('::')]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "df_ratings = pd.read_csv('Data/ml-1m/ratings.csv', sep=',', encoding='latin-1')\n",
    "df_ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000208\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "# df_ratings = df_ratings[0:40000]\n",
    "# print(len(df_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### GENERATING A USER RATING MATRIX FOR REVIEWS OF MOVIES THAT HAVE SUMMARY INFORMATION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "ratings_new_list = []\n",
    "for ix in df_ratings.index:\n",
    "    movie_id = df_ratings.loc[ix]['movie_id']\n",
    "    if float(movie_id) in movie_id_ratings_summary:\n",
    "        df_ratings.loc[[ix],['Summary Present']] = 'Y'\n",
    "        df_ratings.loc[[ix],['Movie Summary ID']] = int(movie_id_ratings_summary[float(movie_id)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings[(df_ratings['Summary Present'] == 'Y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings, df_ratings_test = train_test_split(df_ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "# df_ratings = pd.read_csv('Output/df_ratings.csv')\n",
    "# df_ratings_test = pd.read_csv('Output/df_ratings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_grouped = df_ratings.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5985\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ratings_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = np.zeros(shape=(len(df_ratings_grouped), len(movies_dict)))\n",
    "key = 0\n",
    "row = -1\n",
    "existing_users = []\n",
    "for ix in df_ratings.index:\n",
    "    user_id = df_ratings.loc[ix]['user_id']\n",
    "    if user_id not in existing_users:\n",
    "        existing_users.append(user_id)\n",
    "        row = row + 1\n",
    "        #print(row)\n",
    "        users_dict[user_id] = row\n",
    "\n",
    "    movie_id = df_ratings.loc[ix]['movie_id']\n",
    "    ratings_val = df_ratings.loc[ix]['rating']\n",
    "    #print(type(movie_id))\n",
    "\n",
    "    if float(movie_id) in movie_id_ratings_summary:\n",
    "        movie_id_summary = movie_id_ratings_summary[movie_id]\n",
    "        #print(type(movie_id_summary))\n",
    "        if str(movie_id_summary) in movies_dict:\n",
    "            #print('yes')\n",
    "            col = list(movies_dict).index(str(movie_id_summary))\n",
    "            ratings_matrix[row][col] = ratings_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/users-dict.txt', 'w') as f:\n",
    "    print(users_dict, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Output/ratings-matrix.txt', 'w') as f:\n",
    "    print(ratings_matrix, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING\n",
    "# ratings_matrix = np.zeros(shape=(len(df_ratings_grouped), len(movies_dict)))\n",
    "# f = open('ratings-matrix.txt', 'r')\n",
    "# row_num = 0\n",
    "# col_num = 0\n",
    "# for line in f:\n",
    "#     for i in range(len(line)):\n",
    "#         if line[i] == '0' or line[i] == '1' or line[i] == '2' or line[i] == '3' or line[i] == '4' or line[i] == '5':\n",
    "#             ratings_matrix[row_num][col_num] = int(line[i])\n",
    "#             col_num = col_num + 1\n",
    "#         if line[i] == ']':\n",
    "#             row_num = row_num + 1\n",
    "#             col_num = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_prediction(user_id, movie_id):\n",
    "    movie_id = str(movie_id)\n",
    "    #print(type(movie_id))\n",
    "    movie_flag = False\n",
    "\n",
    "    # if movie_id not in movies_dict.keys():\n",
    "    #     return 0\n",
    "    for key, value in movies_dict.items():\n",
    "        if movie_id == key:\n",
    "            movie_flag = True\n",
    "    \n",
    "    if not movie_flag:\n",
    "        print(\"Error 1\")\n",
    "        return 0\n",
    "    if user_id not in users_dict:\n",
    "        print(\"Error 2\")\n",
    "        return 0\n",
    "    \n",
    "    pred_rating = 0\n",
    "    count = 0\n",
    "\n",
    "    user_ix = list(users_dict).index(user_id)\n",
    "\n",
    "    for key, value in movies_dict.items():\n",
    "        if key == movie_id:\n",
    "            continue\n",
    "        else:\n",
    "            movie_ix = list(movies_dict).index(key)\n",
    "            #movie_sim = cosine_sim(key, movie_id)\n",
    "            movie_num_1 = list(movies_dict).index(key)\n",
    "            movie_num_2 = list(movies_dict).index(movie_id)\n",
    "            movie_sim = cosine_sim_matrix[movie_num_1][movie_num_2]\n",
    "            if movie_sim > average:\n",
    "                if ratings_matrix[user_ix][movie_ix] != 0:\n",
    "                    count = count + movie_sim\n",
    "                    pred_rating = pred_rating + movie_sim * ratings_matrix[user_ix][movie_ix]\n",
    "    \n",
    "    if count != 0:\n",
    "        return pred_rating / count\n",
    "        print('Error 4')\n",
    "    else:\n",
    "        return 0\n",
    "        print('Error 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ratings = []\n",
    "count = 0\n",
    "for ix in df_ratings_test.index:\n",
    "    movie_id = df_ratings_test.loc[ix]['Movie Summary ID']\n",
    "    movie_id = str(int(movie_id))\n",
    "    user_id = df_ratings_test.loc[ix]['user_id']\n",
    "    pred_rating = ratings_prediction(user_id, movie_id)\n",
    "    pred_ratings.append(pred_rating)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_test['Predicted Ratings 3'] = pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_rating_list = []\n",
    "pred_rating_list = []\n",
    "#c = 0\n",
    "for ix in df_ratings_test.index:\n",
    "    #c = c + 1\n",
    "    actual_rating = df_ratings_test.loc[ix]['rating']\n",
    "    pred_rating = df_ratings_test.loc[ix]['Predicted Ratings 3']\n",
    "    if pred_rating != 0:\n",
    "        actual_rating_list.append(actual_rating)\n",
    "        pred_rating_list.append(pred_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv('Output/df_ratings.csv')\n",
    "df_ratings_test.to_csv('Output/df_ratings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(actual_rating_list)):\n",
    "    if actual_rating_list[i] == round(pred_rating_list[i]):\n",
    "        correct = correct + 1\n",
    "    total = total + 1\n",
    "\n",
    "average = correct/total\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_rating_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36a7ae3c59622fb61aaa99c54d5af07e1450a78e5cabfef5028bf902ee2cc3f7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
